---
phase: 05-memory-embeddings
plan: 02
type: execute
wave: 2
depends_on: [05-01]
files_modified:
  - crates/blufio-memory/src/retriever.rs
  - crates/blufio-memory/src/extractor.rs
  - crates/blufio-memory/src/provider.rs
  - crates/blufio-memory/src/lib.rs
autonomous: true
requirements:
  - MEM-01
  - MEM-03

must_haves:
  truths:
    - HybridRetriever combines vector similarity and BM25 results via RRF fusion
    - Only memories above the similarity threshold are returned
    - Retrieval completes within 100ms for typical query against 1000 memories
    - MemoryExtractor calls Haiku to extract facts from conversation text
    - Extraction returns structured facts with source and confidence metadata
    - MemoryProvider implements ConditionalProvider and injects relevant memories as structured block
    - MemoryProvider returns empty Vec when no memories exceed threshold
  artifacts:
    - crates/blufio-memory/src/retriever.rs
    - crates/blufio-memory/src/extractor.rs
    - crates/blufio-memory/src/provider.rs
  key_links:
    - HybridRetriever uses OnnxEmbedder for query embedding and MemoryStore for search
    - MemoryExtractor uses ProviderAdapter (Anthropic) for Haiku extraction calls
    - MemoryProvider implements ConditionalProvider from blufio-context
    - MemoryProvider uses HybridRetriever internally for per-turn retrieval
---

<objective>
Build the hybrid retriever (vector + BM25 + RRF fusion), LLM-based memory extraction pipeline, and ConditionalProvider implementation that injects relevant memories into the context window.

Purpose: This plan creates the intelligence layer -- how memories are found (retriever), created (extractor), and surfaced (provider). Plan 01 built the data layer; this plan builds the query and creation layer.

Output: HybridRetriever for searching, MemoryExtractor for fact extraction via Haiku, MemoryProvider implementing ConditionalProvider for context injection.
</objective>

<execution_context>
@/Users/suman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/suman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/05-memory-embeddings/05-CONTEXT.md
@.planning/phases/05-memory-embeddings/05-RESEARCH.md
@.planning/phases/05-memory-embeddings/05-01-SUMMARY.md

@crates/blufio-context/src/conditional.rs
@crates/blufio-context/src/lib.rs
@crates/blufio-core/src/types.rs
@crates/blufio-core/src/traits/embedding.rs

<interfaces>
<!-- Key types from Plan 01 that this plan consumes -->

From crates/blufio-memory/src/types.rs (created in Plan 01):
```rust
pub struct Memory {
    pub id: String,
    pub content: String,
    pub embedding: Vec<f32>,
    pub source: MemorySource,
    pub confidence: f64,
    pub status: MemoryStatus,
    pub superseded_by: Option<String>,
    pub session_id: Option<String>,
    pub created_at: String,
    pub updated_at: String,
}

pub enum MemorySource { Explicit, Extracted }
pub enum MemoryStatus { Active, Superseded, Forgotten }

pub fn cosine_similarity(a: &[f32], b: &[f32]) -> f32;
pub fn vec_to_blob(vec: &[f32]) -> Vec<u8>;
pub fn blob_to_vec(blob: &[u8]) -> Vec<f32>;
```

From crates/blufio-memory/src/store.rs (created in Plan 01):
```rust
pub struct MemoryStore { /* wraps tokio_rusqlite::Connection */ }
impl MemoryStore {
    pub async fn save(&self, memory: &Memory) -> Result<(), BlufioError>;
    pub async fn get_active_embeddings(&self) -> Result<Vec<(String, Vec<f32>)>, BlufioError>;
    pub async fn search_bm25(&self, query: &str, limit: usize) -> Result<Vec<(String, f64)>, BlufioError>;
    pub async fn get_memories_by_ids(&self, ids: &[String]) -> Result<Vec<Memory>, BlufioError>;
    pub async fn soft_delete(&self, id: &str) -> Result<(), BlufioError>;
    pub async fn supersede(&self, old_id: &str, new_id: &str) -> Result<(), BlufioError>;
}
```

From crates/blufio-memory/src/embedder.rs (created in Plan 01):
```rust
pub struct OnnxEmbedder { /* Session + Tokenizer */ }
impl OnnxEmbedder {
    pub fn new(model_path: &Path) -> Result<Self, BlufioError>;
}
// Implements EmbeddingAdapter: embed(EmbeddingInput) -> Result<EmbeddingOutput>
```

From crates/blufio-context/src/conditional.rs:
```rust
#[async_trait]
pub trait ConditionalProvider: Send + Sync {
    async fn provide_context(&self, session_id: &str) -> Result<Vec<ProviderMessage>, BlufioError>;
}
```

From crates/blufio-config/src/model.rs (updated in Plan 01):
```rust
pub struct MemoryConfig {
    pub enabled: bool,
    pub similarity_threshold: f64,
    pub model_name: String,
    pub extraction_model: String,
    pub idle_timeout_secs: u64,
    pub max_retrieval_results: usize,
}
```
</interfaces>
</context>

<tasks>

<task type="auto" tdd="true">
  <name>Task 1: Build hybrid retriever with vector search, BM25, and RRF fusion</name>
  <files>
    crates/blufio-memory/src/retriever.rs,
    crates/blufio-memory/src/lib.rs
  </files>
  <behavior>
    - Test 1: RRF fusion with k=60 correctly merges two ranked lists -- document appearing in both lists gets higher score
    - Test 2: RRF fusion handles disjoint lists -- documents unique to one list still appear in output
    - Test 3: RRF fusion with empty lists returns empty result
    - Test 4: vector_search returns memories ranked by cosine similarity descending
    - Test 5: vector_search filters by similarity threshold -- memories below threshold excluded
    - Test 6: retrieve combines vector and BM25 results, returns Memory structs ranked by RRF score
    - Test 7: retrieve with no matching memories returns empty Vec
    - Test 8: confidence score boosts retrieval ranking -- explicit memories rank higher on ties
  </behavior>
  <action>
  Create `crates/blufio-memory/src/retriever.rs`:

  **HybridRetriever struct:**
  ```rust
  pub struct HybridRetriever {
      store: Arc<MemoryStore>,
      embedder: Arc<OnnxEmbedder>,
      config: MemoryConfig,
  }
  ```

  **Core methods:**

  1. `pub async fn retrieve(&self, query: &str) -> Result<Vec<ScoredMemory>, BlufioError>`:
     - Embed the query text: `embedder.embed(EmbeddingInput { texts: vec![query.into()] })`
     - Run vector search: `self.vector_search(&query_embedding).await`
     - Run BM25 search: `self.store.search_bm25(query, self.config.max_retrieval_results).await`
     - Fuse results with RRF: `reciprocal_rank_fusion(&vector_results, &bm25_results, 60.0)`
     - Fetch full Memory structs for top results: `self.store.get_memories_by_ids(&top_ids).await`
     - Apply confidence boost: multiply RRF score by memory.confidence (explicit=0.9 > extracted=0.6)
     - Sort by boosted score descending
     - Return Vec<ScoredMemory>

  2. `async fn vector_search(&self, query_embedding: &[f32]) -> Result<Vec<(String, f32)>, BlufioError>`:
     - Load all active embeddings: `self.store.get_active_embeddings().await`
     - Compute cosine_similarity between query and each stored embedding
     - Filter by `self.config.similarity_threshold`
     - Sort by similarity descending
     - Return top `max_retrieval_results` as (id, similarity) pairs

  3. `fn reciprocal_rank_fusion(vector_results, bm25_results, k) -> Vec<(String, f32)>`:
     - Standard RRF: score(d) = sum(1/(k + rank_i)) for each list where d appears
     - k=60 per research literature
     - Sort by fused score descending

  **ScoredMemory type:**
  ```rust
  pub struct ScoredMemory {
      pub memory: Memory,
      pub score: f32,
  }
  ```

  Update lib.rs to export retriever module and HybridRetriever.
  </action>
  <verify>
    <automated>cargo test -p blufio-memory retriever -- --nocapture 2>&1 | tail -20</automated>
  </verify>
  <done>
  - HybridRetriever combines vector similarity + BM25 via RRF
  - Similarity threshold filtering works correctly
  - Confidence-based boosting gives explicit memories priority
  - RRF fusion produces correct merged rankings
  - All retriever tests pass
  </done>
</task>

<task type="auto" tdd="true">
  <name>Task 2: Build memory extractor and ConditionalProvider</name>
  <files>
    crates/blufio-memory/src/extractor.rs,
    crates/blufio-memory/src/provider.rs,
    crates/blufio-memory/src/lib.rs
  </files>
  <behavior>
    - Test 1: Extraction prompt includes conversation text and requests JSON array output
    - Test 2: parse_extraction_response parses valid JSON array of facts
    - Test 3: parse_extraction_response handles empty array (no facts) without error
    - Test 4: parse_extraction_response handles malformed JSON gracefully (returns empty Vec, not error)
    - Test 5: Explicit memories ("remember this: X") get confidence 0.9, extracted get 0.6
    - Test 6: MemoryProvider::provide_context returns ProviderMessage with "## Relevant Memories" header
    - Test 7: MemoryProvider::provide_context returns empty Vec when no memories exceed threshold
    - Test 8: MemoryProvider formats memories as "- [fact]" bullet list in the ProviderMessage
    - Test 9: Deduplication -- if extraction produces a fact very similar to existing memory, it is not stored again
  </behavior>
  <action>
  **Step 1: Create extractor.rs**

  MemoryExtractor handles LLM-based fact extraction:

  ```rust
  pub struct MemoryExtractor {
      store: Arc<MemoryStore>,
      embedder: Arc<OnnxEmbedder>,
      extraction_model: String,
  }
  ```

  Methods:

  1. `pub async fn extract_from_conversation(&self, provider: &dyn ProviderAdapter, session_id: &str, conversation: &[ProviderMessage]) -> Result<Vec<Memory>, BlufioError>`:
     - Build extraction prompt by concatenating conversation messages into readable format
     - Call provider with extraction_model (Haiku) and the prompt
     - Parse JSON response into extracted facts
     - For each fact:
       - Generate embedding via embedder
       - Check for duplicates: if cosine_similarity > 0.9 with any active memory, skip (deduplication)
       - Check for contradictions: if similar memory exists (cosine > 0.7) with conflicting content, supersede old
       - Create Memory with source=Extracted, confidence=0.6
       - Save via store
     - Return list of newly created memories

  2. `pub async fn extract_explicit(&self, text: &str, session_id: &str) -> Result<Memory, BlufioError>`:
     - Strip "remember this:" or "remember that" prefix if present
     - Generate embedding for the text
     - Check for duplicates (same as above)
     - Create Memory with source=Explicit, confidence=0.9
     - Save and return

  3. `fn build_extraction_prompt(conversation: &[ProviderMessage]) -> String`:
     - Format conversation as "User: ...\nAssistant: ..." blocks
     - Wrap with the EXTRACTION_PROMPT constant from research

  4. `fn parse_extraction_response(response: &str) -> Vec<ExtractedFact>`:
     - Parse JSON array, handle markdown code blocks wrapping
     - On parse failure, log warning and return empty Vec (don't fail the whole extraction)

  ```rust
  #[derive(Debug, Deserialize)]
  struct ExtractedFact {
      content: String,
      category: String,
  }
  ```

  The extraction prompt (constant):
  ```rust
  const EXTRACTION_PROMPT: &str = r#"Extract factual information from this conversation that would be useful to remember for future conversations. Output as JSON array.

  For each fact:
  - "content": The fact as a standalone statement (e.g., "The user's dog is named Max")
  - "category": One of: personal, preference, project, decision, instruction, outcome

  Only include facts that are:
  1. Stated by the user (not the assistant)
  2. Specific and factual (not opinions unless explicitly stated as preferences)
  3. Likely to be relevant in future conversations

  If no memorable facts, return an empty array: []

  Conversation:
  {conversation}

  Output JSON array only, no explanation:"#;
  ```

  **Step 2: Create provider.rs**

  MemoryProvider implements ConditionalProvider:

  ```rust
  pub struct MemoryProvider {
      retriever: Arc<HybridRetriever>,
  }
  ```

  Implement ConditionalProvider:
  ```rust
  #[async_trait]
  impl ConditionalProvider for MemoryProvider {
      async fn provide_context(&self, session_id: &str) -> Result<Vec<ProviderMessage>, BlufioError> {
          // The session_id is used as the query context --
          // but we actually need the current turn content.
          // For now, retrieve based on session context.
          // The integration (Plan 03) will pass the current user message
          // via a shared state mechanism.

          // Get current query from shared state (set by session actor before assembly)
          let query = self.get_current_query(session_id).await?;
          if query.is_empty() {
              return Ok(vec![]);
          }

          let memories = self.retriever.retrieve(&query).await?;
          if memories.is_empty() {
              return Ok(vec![]);
          }

          // Format as structured memory block
          let mut memory_text = String::from("## Relevant Memories\n");
          for scored in &memories {
              memory_text.push_str(&format!("- {}\n", scored.memory.content));
          }

          Ok(vec![ProviderMessage {
              role: "user".to_string(),
              content: vec![ContentBlock::Text { text: memory_text }],
          }])
      }
  }
  ```

  Add a query-passing mechanism:
  ```rust
  impl MemoryProvider {
      pub fn new(retriever: Arc<HybridRetriever>) -> Self {
          Self {
              retriever,
              current_queries: Arc::new(tokio::sync::RwLock::new(HashMap::new())),
          }
      }

      /// Called by SessionActor before context assembly to set the current query.
      pub async fn set_current_query(&self, session_id: &str, query: &str) {
          self.current_queries.write().await.insert(session_id.to_string(), query.to_string());
      }

      /// Called after context assembly to clean up.
      pub async fn clear_current_query(&self, session_id: &str) {
          self.current_queries.write().await.remove(session_id);
      }

      async fn get_current_query(&self, session_id: &str) -> Result<String, BlufioError> {
          Ok(self.current_queries.read().await.get(session_id).cloned().unwrap_or_default())
      }
  }
  ```

  **Step 3: Update lib.rs**

  Add `pub mod extractor;` and `pub mod provider;`.
  Re-export: `pub use extractor::MemoryExtractor;`, `pub use provider::MemoryProvider;`, `pub use retriever::HybridRetriever;`.
  </action>
  <verify>
    <automated>cargo test -p blufio-memory -- --nocapture 2>&1 | tail -30</automated>
  </verify>
  <done>
  - MemoryExtractor builds extraction prompt, parses JSON response, creates Memory structs
  - Extraction deduplication skips facts with >0.9 cosine similarity to existing memories
  - Extraction contradiction detection supersedes conflicting memories
  - Explicit memories get confidence 0.9, extracted get 0.6
  - MemoryProvider implements ConditionalProvider
  - MemoryProvider returns formatted "## Relevant Memories" block when relevant memories exist
  - MemoryProvider returns empty Vec when no memories exceed threshold
  - Query-passing mechanism allows SessionActor to set current turn text
  - All tests pass
  </done>
</task>

</tasks>

<verification>
- `cargo build -p blufio-memory` compiles without errors
- `cargo test -p blufio-memory` all tests pass
- `cargo test --workspace` no regressions
- HybridRetriever correctly fuses vector + BM25 via RRF
- MemoryExtractor produces structured facts from conversation text
- MemoryProvider implements ConditionalProvider correctly
</verification>

<success_criteria>
- HybridRetriever combines vector similarity + BM25 + RRF fusion
- Similarity threshold filtering excludes irrelevant memories
- MemoryExtractor extracts facts via Haiku with deduplication and contradiction handling
- MemoryProvider implements ConditionalProvider, formatting memories as bullet list
- Confidence scoring affects retrieval ranking (explicit > extracted)
- All workspace tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-memory-embeddings/05-02-SUMMARY.md`
</output>
