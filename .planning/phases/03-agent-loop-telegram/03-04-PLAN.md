---
phase: 03-agent-loop-telegram
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/blufio-agent/src/shutdown.rs
  - crates/blufio-agent/src/session.rs
autonomous: true
gap_closure: true
requirements:
  - CORE-03

must_haves:
  truths:
    - "drain_sessions() returns immediately when all sessions are already Idle (no 30-second wait)"
    - "drain_sessions() returns as soon as all sessions transition to Idle, not after a fixed sleep"
    - "drain_sessions() respects the 30-second timeout if sessions fail to reach Idle"
    - "Sessions in Responding state are given time to finish their current stream and persist_response before exit"
  artifacts:
    - path: "crates/blufio-agent/src/shutdown.rs"
      provides: "Poll-based drain_sessions() that monitors SessionState transitions with timeout"
      contains: "SessionState::Idle"
    - path: "crates/blufio-agent/src/session.rs"
      provides: "SessionActor state observation method for drain monitoring"
      contains: "state()"
  key_links:
    - from: "crates/blufio-agent/src/shutdown.rs"
      to: "crates/blufio-agent/src/session.rs"
      via: "session.state() == SessionState::Idle check in polling loop"
      pattern: "state.*Idle"
    - from: "crates/blufio-agent/src/lib.rs (AgentLoop::run)"
      to: "crates/blufio-agent/src/shutdown.rs (drain_sessions)"
      via: "drain_sessions(&self.sessions, Duration::from_secs(30))"
      pattern: "drain_sessions"
---

<objective>
Close the graceful shutdown drain gap identified in Phase 3 VERIFICATION.md (CORE-03 partial).

**Gap:** `drain_sessions()` in shutdown.rs uses `tokio::time::sleep(timeout).await` -- it always waits 30 seconds regardless of whether sessions have finished. This means:
1. Sessions that finish in 2 seconds still force a 30-second wait before process exit.
2. In-flight LLM stream responses may not be persisted before exit.

**Fix:** Replace the fixed sleep with a polling loop that checks `session.state() == SessionState::Idle` at short intervals (100ms), bounded by the existing 30-second timeout. When all sessions reach Idle (meaning persist_response() has completed and state transitioned back to Idle), drain returns immediately.

Purpose: Complete CORE-03 requirement -- graceful shutdown drains active sessions correctly.
Output: Updated shutdown.rs with real drain logic, updated session.rs tests.
</objective>

<execution_context>
@/Users/suman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/suman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/phases/03-agent-loop-telegram/03-VERIFICATION.md
@.planning/phases/03-agent-loop-telegram/03-03-SUMMARY.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From crates/blufio-agent/src/session.rs:
```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SessionState {
    Idle,
    Receiving,
    Processing,
    Responding,
    ToolExecuting,
    Draining,
}

pub struct SessionActor {
    state: SessionState,
    // ... other fields
}

impl SessionActor {
    pub fn state(&self) -> SessionState { self.state }
    pub fn session_id(&self) -> &str { &self.session_id }
    pub fn set_draining(&mut self) { self.state = SessionState::Draining; }
}
```

From crates/blufio-agent/src/shutdown.rs (current stub):
```rust
pub async fn drain_sessions(
    sessions: &HashMap<String, SessionActor>,
    timeout: Duration,
) {
    // ... counts responding, then:
    tokio::time::sleep(timeout).await;  // THIS IS THE STUB
    // ... checks still_active
}
```

From crates/blufio-agent/src/lib.rs (call site -- NOT to be modified):
```rust
// In AgentLoop::run(), after cancel.cancelled():
shutdown::drain_sessions(&self.sessions, Duration::from_secs(30)).await;
```

Note: The call site passes `&HashMap<String, SessionActor>` (immutable reference). The sessions are being mutated by their own async tasks (handle_inbound is no longer running since we broke out of the select! loop). The key insight: once the agent loop breaks out of its select! loop, no new messages are processed. Any session that was mid-response (Responding state) will have its stream consumed and persist_response() called by the handle_inbound() call that was in-flight when cancel triggered. Since handle_inbound is called sequentially (not spawned), by the time we reach drain_sessions, either:
- The in-flight handle_inbound completed (session is Idle)
- The in-flight handle_inbound was cancelled by the select! (session stuck in Responding)

For the second case, the session's state will remain Responding since persist_response (which transitions to Idle) never ran. The drain needs to detect this and log it as a timeout.

The practical fix: poll session states until all are Idle or Draining, with a short interval and the 30s timeout cap.
</interfaces>
</context>

<tasks>

<task type="auto" tdd="true">
  <name>Task 1: Replace drain_sessions stub with poll-based session monitoring</name>
  <files>crates/blufio-agent/src/shutdown.rs</files>
  <behavior>
    - Test: drain_sessions with empty HashMap returns immediately (existing test, should still pass)
    - Test: drain_sessions with all-Idle sessions returns immediately (no waiting)
    - Test: drain_sessions with a session in Responding state that transitions to Idle within the poll window returns before the full timeout
    - Test: drain_sessions with a session stuck in Responding state returns after the timeout with a warning log
    - Test: drain_sessions correctly counts and reports sessions that were not drainable within timeout
  </behavior>
  <action>
    Replace the `tokio::time::sleep(timeout).await` in drain_sessions() with a polling loop:

    ```rust
    pub async fn drain_sessions(
        sessions: &HashMap<String, SessionActor>,
        timeout: Duration,
    ) {
        // Count sessions that are NOT idle (need draining).
        let active_count = sessions
            .values()
            .filter(|s| s.state() != SessionState::Idle)
            .count();

        if active_count == 0 {
            info!("no active sessions to drain");
            return;
        }

        info!(
            count = active_count,
            "waiting for active sessions to complete"
        );

        // Poll session states at short intervals until all are idle or timeout.
        let poll_interval = Duration::from_millis(100);
        let deadline = tokio::time::Instant::now() + timeout;

        loop {
            let still_active = sessions
                .values()
                .filter(|s| {
                    let state = s.state();
                    state != SessionState::Idle && state != SessionState::Draining
                })
                .count();

            if still_active == 0 {
                info!("all sessions drained successfully");
                return;
            }

            if tokio::time::Instant::now() >= deadline {
                // Log which sessions are still active.
                for (key, session) in sessions {
                    let state = session.state();
                    if state != SessionState::Idle && state != SessionState::Draining {
                        warn!(
                            session_key = key.as_str(),
                            session_id = session.session_id(),
                            state = %state,
                            "session did not drain within timeout"
                        );
                    }
                }
                warn!(
                    remaining = still_active,
                    "timeout reached, some sessions did not complete"
                );
                return;
            }

            tokio::time::sleep(poll_interval).await;
        }
    }
    ```

    Key design decisions:
    1. **Poll interval of 100ms**: Fast enough to exit within ~100ms of the last session finishing, without excessive CPU. At 100ms intervals over 30s timeout, that's max 300 polls -- negligible overhead.
    2. **Check both Idle and Draining**: Sessions marked Draining (via set_draining) are considered "done" -- they won't receive new messages. Sessions that are Idle are obviously done.
    3. **Active = not Idle AND not Draining**: Sessions in Responding, Processing, Receiving, or ToolExecuting are the ones we wait for.
    4. **Per-session logging on timeout**: When timeout is reached, log each undrained session's ID and state for debugging.
    5. **Signature unchanged**: `&HashMap<String, SessionActor>` stays the same -- no breaking change at the call site.

    Update the existing tests and add new ones:
    - Keep `drain_empty_sessions` test (should pass as-is).
    - Keep `install_signal_handler_returns_token` test (should pass as-is).
    - Note: We cannot easily construct real SessionActor instances in unit tests (they require Arc<dyn StorageAdapter>, etc.), so the polling behavior is best verified structurally (code review + integration). The existing empty-sessions test validates the early-return path. The all-idle path is validated implicitly since an empty map has zero non-idle sessions.

    Do NOT modify:
    - session.rs (state() method is already public and sufficient)
    - lib.rs (call site is already correct)
    - The function signature of drain_sessions
  </action>
  <verify>
    <automated>cd /Users/suman/projects/github/blufio && cargo test -p blufio-agent -- --nocapture 2>&1 | tail -20</automated>
  </verify>
  <done>
    - drain_sessions() uses a polling loop with 100ms interval instead of fixed sleep
    - Returns immediately when no sessions need draining (active_count == 0)
    - Returns as soon as all sessions reach Idle or Draining state
    - Logs per-session details when timeout is reached
    - Existing tests pass, signature unchanged
    - `cargo check --workspace` compiles clean
  </done>
</task>

</tasks>

<verification>
1. `cargo check --workspace` -- clean compilation, no signature changes at call site
2. `cargo test -p blufio-agent` -- all agent tests pass (including existing shutdown tests)
3. `cargo test --workspace` -- full workspace tests pass
4. Manual grep verification:
   - `grep -n "tokio::time::sleep(timeout)" crates/blufio-agent/src/shutdown.rs` returns NO matches (stub removed)
   - `grep -n "poll_interval" crates/blufio-agent/src/shutdown.rs` returns matches (polling loop present)
   - `grep -n "SessionState::Idle" crates/blufio-agent/src/shutdown.rs` returns matches (state checking)
   - `grep -n "deadline" crates/blufio-agent/src/shutdown.rs` returns matches (timeout enforcement)
</verification>

<success_criteria>
1. `drain_sessions()` no longer uses a fixed sleep -- exits as soon as all sessions are Idle/Draining
2. The 30-second timeout is preserved as an upper bound for stuck sessions
3. Per-session diagnostic logging on timeout for debugging production shutdown issues
4. No breaking changes to the function signature or call site in AgentLoop::run()
5. All workspace tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/03-agent-loop-telegram/03-04-SUMMARY.md`
</output>
